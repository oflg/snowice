{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装环境\n",
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "# Pkg.add(\"DataFrames\")\n",
    "# Pkg.add(\"PyCall\")\n",
    "Pkg.instantiate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, LightXML, DataFrames, PyCall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cn (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@pyimport deep_translator\n",
    "\n",
    "function cn(text)\n",
    "    if text == \"International\"\n",
    "        \"国际\"\n",
    "    elseif text == \"European Union\"\n",
    "        \"欧盟\"\n",
    "    elseif text == \"National Cryosphere Desert Data Center\"\n",
    "        \"国家冰川冻土沙漠科学数据中心\"\n",
    "    else\n",
    "        deep_translator.GoogleTranslator(source=\"auto\", target=\"zh-CN\").translate(text)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@pyimport pycountry\n",
    "\n",
    "function country(alpha_3)\n",
    "    if alpha_3 == \"AAA\"\n",
    "        \"International\"\n",
    "    elseif alpha_3 == \"EEC\"\n",
    "        \"European Union\"\n",
    "    else\n",
    "        pycountry.countries.get(alpha_3=alpha_3).name\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# country(\"AAA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/home/oflg/Code/ucas/论文/雪冰科学数据中心\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "root_path = joinpath(dirname(@__FILE__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = CSV.read(joinpath(root_path, \"data\", \"snow_ice_data.csv\"), DataFrame)\n",
    "metas = df[!, :metadata];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "国家冰雪数据中心\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开放测高\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NASA 国家冰雪数据中心分布式主动档案中心\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "先进的北极合作数据和信息服务\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "剑桥世界冰川学数据中心\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "冰盖遥感中心\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "国家冰冻圈沙漠数据中心\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "国家极地研究所科学数据库\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中分辨率成像光谱仪\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "综合气候数据中心\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARM 数据中心\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOAA 国家环境信息中心 - 古气候数据\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特拉\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOAA 的气候数据记录计划\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "由 EOSDIS 提供支持的 Earthdata\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "美国南极计划数据中心\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "巴罗地区信息数据库\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "物理海洋学分布式主动档案中心\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "格雷斯ISDC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TerraSAR-X TOR\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "世界气候数据中心\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "专业的\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "国际Argo计划\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"/home/oflg/Code/ucas/论文/雪冰科学数据中心/data/snow_ice_info.csv\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "infos = []\n",
    "\n",
    "for meta in metas\n",
    "    # 名称、网址、所属机构、所在国家或国际组织、数据中心简介、特色及特有资源。\n",
    "    xml = parse_string(meta)\n",
    "    xml_root = root(xml)\n",
    "    repo = find_element(xml_root, \"repository\")\n",
    "    orgIdentifier = content(find_element(repo, \"re3data.orgIdentifier\"))\n",
    "    repositoryName = content(find_element(repo, \"repositoryName\"))\n",
    "    repositoryNameCn = cn(repositoryName)\n",
    "    repositoryURL = content(find_element(repo, \"repositoryURL\"))\n",
    "    description = content(find_element(repo, \"description\"))\n",
    "    descriptionCn = cn(description)\n",
    "\n",
    "    if occursin(\"<<<\", description)\n",
    "        continue\n",
    "    end\n",
    "\n",
    "    # 国家、机构相关数据\n",
    "    institutions_xml = get_elements_by_tagname(repo, \"institution\")\n",
    "    institutions_array = []\n",
    "    institutionsCn_array = []\n",
    "    countries_array = []\n",
    "    countriesCn_array = []\n",
    "    println(repositoryNameCn)\n",
    "    \n",
    "    for inst in institutions_xml\n",
    "        institutionName = content(find_element(inst, \"institutionName\"))\n",
    "        institutionNameCn = cn(institutionName)\n",
    "        institutionCountry = country(content(find_element(inst, \"institutionCountry\")))\n",
    "        institutionCountryCn = cn(institutionCountry)\n",
    "        inst = \"$institutionName($institutionCountry)\"\n",
    "        instCn = \"$institutionNameCn($institutionCountryCn)\"\n",
    "        push!(countries_array, institutionCountry)\n",
    "        push!(countriesCn_array, institutionCountryCn)\n",
    "        push!(institutions_array, inst)\n",
    "        push!(institutionsCn_array, instCn)\n",
    "    end\n",
    "\n",
    "\n",
    "    if \"International\" in countries_array || \"European Union\" in countries_array\n",
    "        continue\n",
    "    end\n",
    "\n",
    "    countries = join(unique(countries_array), \"; \")\n",
    "    countriesCn = join(unique(countriesCn_array), \"; \")\n",
    "    institutions = join(institutions_array, \"; \")\n",
    "    institutionsCn = join(institutionsCn_array, \"; \")\n",
    "    contentType_xml = get_elements_by_tagname(repo, \"contentType\")\n",
    "    contentTypes_array = []\n",
    "    contentTypesCn_array = []\n",
    "\n",
    "    for cont in contentType_xml\n",
    "        contentType = content(cont)\n",
    "        contentTypeCn = cn(contentType)\n",
    "        push!(contentTypes_array, contentType)\n",
    "        push!(contentTypesCn_array, contentTypeCn)\n",
    "    end\n",
    "\n",
    "    contentTypes = join(contentTypes_array, \"; \")\n",
    "    contentTypesCn = join(contentTypesCn_array, \"; \")\n",
    "\n",
    "\n",
    "    # 将元数据添加到数组中\n",
    "    push!(infos, (\n",
    "        orgIdentifier=orgIdentifier,\n",
    "        repositoryName=repositoryName,\n",
    "        repositoryNameCn=repositoryNameCn,\n",
    "        repositoryURL=repositoryURL,\n",
    "        countries=countries,\n",
    "        countriesCn=countriesCn,\n",
    "        institutions=institutions,\n",
    "        institutionsCn=institutionsCn,\n",
    "        contentTypes=contentTypes,\n",
    "        contentTypesCn=contentTypesCn,\n",
    "        description=description,\n",
    "        descriptionCn=descriptionCn,\n",
    "    ))\n",
    "    # break\n",
    "end\n",
    "\n",
    "# text\n",
    "# 将数组写入csv文件\n",
    "CSV.write(joinpath(root_path, \"data\", \"snow_ice_info.csv\"), infos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
